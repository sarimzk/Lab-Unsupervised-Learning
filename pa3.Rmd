---
title: "Programming Assignment 3: Unsupervised Learning"
author: "Sarim | SARIMZIA | 50245868"
date: "16 May 2018"
output: html_document
---
***
#Task 1
##10.4 Principal Component Analysis
```{r}
states = row.names(USArrests)
states
```

```{r}
names(USArrests)
```

```{r}
apply(USArrests, 2 , mean)
```

```{r}
apply(USArrests, 2, var)
```

```{r}
pr.out=prcomp(USArrests, scale=TRUE)
```

```{r}
names(pr.out)
```

```{r}
pr.out$center
pr.out$scale
```

```{r}
pr.out$rotation
```

```{r}
dim(pr.out$x)
```

```{r, fig.align='center', fig.width=8, fig.height=8}
biplot(pr.out, scale=0)
```

```{r, fig.align='center', fig.width=8, fig.height=8}
pr.out$rotation=-pr.out$rotation
pr.out$x=-pr.out$x
biplot(pr.out, scale=0)
```

```{r}
pr.out$sdev
```

```{r}
pr.var=pr.out$sdev^2
pr.var
```

```{r}
pve=pr.var/sum(pr.var)
pve
```

```{r, fig.align='center'}
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", ylim=c(0,1), type='b')
plot(cumsum(pve), xlab="Principal component", ylab="Cumulative Proportion of Variance Explained", ylim=c(0,1), type='b')
```

```{r}
a=c(1,2,8,-3)
cumsum(a)
```

***
#Task 2
##10.5 Clustering

```{r, fig.align='center'}
set.seed(2)
x=matrix(rnorm(50*2), ncol=2)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
km.out=kmeans(x,2,nstart=20)
km.out$cluster
plot(x, col=(km.out$cluster +1), main="K-Means Clustering Results with K=2", xlab="", ylab="", pch=20, cex=2)
```

```{r fig.align='center'}
set.seed(4)
km.out=kmeans(x,3,nstart=20)
km.out
plot(x, col=(km.out$cluster +1), main="K-Means Clustering Results with K=3", xlab="", ylab="", pch=20, cex=2)
```

```{r}
set.seed(3)
km.out=kmeans(x,3, nstart =1)
km.out$tot.withinss
km.out=kmeans(x,3,nstart=20)
km.out$tot.withinss
```

```{r, fig.align='center'}
hc.complete=hclust(dist(x), method="complete")
hc.average=hclust(dist(x), method ="average")
hc.single=hclust(dist(x), method ="single")
par(mfrow=c(1,3))
plot(hc.complete, main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)
```

```{r}
cutree(hc.complete, 2)
cutree(hc.average, 2)
cutree(hc.single, 2)
cutree(hc.single, 4)
```

```{r, fig.align='center'}
xsc=scale(x)
plot(hclust(dist(xsc), method="complete"), main="Hierarchical Clustering with Scaled Features ")
```

```{r, fig.align='center'}
x=matrix(rnorm(30*3), ncol=3)
dd=as.dist(1-cor(t(x)))
plot(hclust(dd, method ="complete"), main="Complete Linkage with Correlation-Based Distance", xlab="", sub ="")
```

***
#Task 3
##10.6 NCI60 Data Example

```{r}
library(ISLR)
nci.labs=NCI60$labs
nci.data=NCI60$data
```

```{r}
dim(nci.data)
nci.labs[1:4]
table(nci.labs)
```

```{r}
pr.out=prcomp(nci.data, scale=TRUE)
```

```{r}
Cols=function(vec){
 cols=rainbow(length(unique(vec)))
 return(cols[as.numeric(as.factor(vec))])
}
```

```{r, fig.align='center'}
par(mfrow=c(1,2))
plot(pr.out$x[,1:2], col=Cols(nci.labs), pch=19, xlab="Z1", ylab="Z2")
plot(pr.out$x[,c(1,3)], col=Cols(nci.labs), pch=19, xlab="Z1",ylab="Z3")

```

```{r}
summary(pr.out)
```

```{r fig.align='center'}
plot(pr.out)
```

```{r fig.align='center'}
pve =100*pr.out$sdev^2/sum(pr.out$sdev^2)
plot(pve, type="o", ylab="PVE", xlab=" Principal Component", col="blue")
plot(cumsum(pve), type="o", ylab="Cumulative PVE", xlab="Principal Component", col="brown3")
```

```{r, fig.align='center', fig.width= 14}
sd.data=scale(nci.data)
```

```{r}
par(mfrow=c(1,3))
data.dist=dist(sd.data)
```

```{r, fig.align='center', fig.width= 14}
plot(hclust(data.dist), labels=nci.labs, main="Complete Linkage", xlab="", sub="", ylab="")
```

```{r, fig.align='center', fig.width= 14}
plot(hclust(data.dist, method ="average"), labels=nci.labs, main="Average Linkage", xlab="", sub="", ylab="")
```



```{r, fig.align='center', fig.width= 14}
plot(hclust(data.dist, method ="single"), labels=nci.labs,
main="Single Linkage", xlab="", sub="", ylab="")
```

```{r}
hc.out=hclust(dist(sd.data))
hc.clusters=cutree(hc.out, 4)
table(hc.clusters, nci.labs)
```

```{r fig.align='center', fig.width=14}
par(mfrow=c(1,1))
plot(hc.out, labels=nci.labs)
abline(h=139, col="red")
```

```{r}
hc.out
```

```{r}
set.seed(2)
km.out=kmeans(sd.data, 4, nstart=20)
km.clusters= km.out$cluster
table(km.clusters, hc.clusters)
```

```{r fig.align='center', fig.width=14}
hc.out=hclust(dist(pr.out$x[,1:5]))
plot(hc.out, labels=nci.labs, main="Heir. Clust. on first Five Score Vectors")
table(cutree(hc.out,4), nci.labs)
```

***
#Task 4
##Summary

It took me 2 days to finish this assignment. Although this assignment was just about replicating the code from the book and posting the results, I found it to be extremely helpful in understanding the concepts of the unsupervised learning, clustering and principal component analysis. The assignment was easy to complete, but understanding the underlying concepts took time and I had to refer to various other sources on the internet to understand those concepts. 